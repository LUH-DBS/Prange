% LTex: enabled=false
\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

% \usepackage[left=2.5cm,right=2.5cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{parskip}
\usepackage{lmodern}
\usepackage{nicefrac}

\usepackage{contour}
\usepackage{ulem}
\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.8pt}
\renewcommand{\underline}[1]{%
  \uline{\phantom{#1}}%
  \llap{\contour{white}{#1}}%
}

\usepackage{siunitx}
\sisetup{
    locale=DE,
    group-digits = integer,
    round-mode = places,
    round-precision = 3,
    round-pad = false
}

\usepackage{enumitem}

\usepackage{tabularx} 
\usepackage{ragged2e}
\newcolumntype{L}{>{\RaggedRight}X}
\newcolumntype{R}{>{\RaggedLeft}X}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcommand{\hrc}[1]{\multicolumn{1}{C}{#1}}
\usepackage{multirow}
\usepackage{booktabs}

% \usepackage[dvipsnames]{xcolor, colortbl}
% \definecolor{Gray}{gray}{0.7}
% \definecolor{Lightgray}{gray}{0.9}
% \definecolor{Hellblau}{HTML}{C3F9FD}

\usepackage{csquotes}
\usepackage[noorphans,font=itshape]{quoting}

\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{listings}

\usepackage{fancyhdr}
\usepackage{lastpage}
\fancypagestyle{mainpagestyle}{%
  \fancyhf{}%
  \fancyhead[L]{}%
  \fancyhead[C]{Expose}%
  \fancyhead[R]{\today}%
  \cfoot{Seite \thepage\ von \pageref{LastPage}}%
}  
\fancypagestyle{firstpagestyle}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0mm}%
  \cfoot{Seite \thepage\ von \pageref{LastPage}}
}  
\pagestyle{mainpagestyle}

% \setcounter{secnumdepth}{0}
% \setcounter{tocdepth}{2}

\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000

\usepackage[hidelinks]{hyperref}
\hypersetup{
      pdftitle={Expose},
      pdfsubject={},
      pdfauthor={Janek Prange},
      colorlinks=false,
      pdfpagemode=UseNone
      }
      
% Ltex: enabled=true language=en-US

\begin{document}
\thispagestyle{firstpagestyle}
\begin{center}
  \huge \textbf{Expose}\\[8pt]
  % Zusammenfassung\\[10pt]
  \normalsize Janek Prange\\
  \today
\end{center}

\section{Motivation}
Big collections of data and therefore databases are becoming increasingly important with time as more data is produced with accelerating speed. In the best case, this data is directly saved in a format that contains a lot of metadata such as data types, primary keys and information about dependencies between columns.

In many scenarios however, it is not possible to design a proper schema suited for specific data beforehand. Instead, the data is already present in an arbitrary format or is being taken from other sources such as internet dumps. These use cases require tools to -- as much as possible automatically -- detect the needed metadata from the raw data. % chktex 8

The thesis introduced in this expose tries to propose a new solution to this problem making use of machine learning.


\section{Naive Procedures}\label{sec:naiveProcedures}
One of the main characteristics of a primary key is the uniqueness of its values. Based on that constraint, a naive way of finding primary key candidates would be to search for columns or column combinations which don't have any duplicate values. This could be achieved either by sorting or hashing.

Especially when using a hashing algorithm, the primary key candidates could be found relatively efficiently. It is however necessary to read all values in all columns, which can become a very large amount of data very fast, especially if no single column candidate can be found and column combinations have to be hashed. It could however be possible to increase the efficiency by ignoring some columns, for example the ones containing images or long texts.


\section{Proposed Solution}\label{sec:proposedSolution}
The thesis introduced here will present a solution to find primary keys respectively primary key candidates that is primarily based on a neural network, which will be trained on a large set of tables. The hope is that the network will discover primary key candidates with better efficiency than the naive solution described in Section~\ref{sec:naiveProcedures}.

In addition to the usage of neural networks, there may be other ideas to increase the efficiency of the algorithm. One possibility would be to sample the columns of the table instead of reading all values. This way, the data that has to be retrieved from the database could be reduced which may result in a significant speedup when the algorithm is used with large datasets.

Another opportunity for increased efficiency could be the implementation of a two phase algorithm. In the first phase, columns which can't practicably be primary keys will be eliminated, such as columns containing images, videos or relatively long texts. In the second phase, the neural network would try detecting the best primary key candidates from the remaining columns.

To reduce the scope of the thesis, the focus of the algorithm will be primarily on detecting single column primary key candidates. If the results are promising and there is time left, multicolumn candidates will be included.


\section{Evaluation Method and Metric}
To train the neural network that is at the center of the in Section~\ref{sec:proposedSolution} proposed solution, metrics have to be defined to evaluate the success or failure of the network. In this case, there are two favorable and relatively easy to measure methods, which are the correctness and the efficiency of the algorithm.

A primary key candidate is correct, when it has no duplicate elements and no subset of it is a primary key. These requirements are easy to check, especially if the algorithm is limited to single column candidates.

For the purposes of this thesis, the algorithm is efficient if it is faster and uses less main memory than the naive solution presented in Section~\ref{sec:naiveProcedures}, which will be tested on the same data as the neural network.


\section{Possible Titles}
\begin{itemize}
  \item Enhancing Primary Key Detection using Machine Learning
  \item Improved Primary Key Detection with Neural Networks
\end{itemize}

\end{document}