% LTex: language=en-US enabled=false

@inproceedings{dataXFormer,
  keywords  = {datasets},
  title     = {DataXFormer: A robust transformation discovery system},
  author    = {Abedjan, Ziawasch and Morcos, John and Ilyas, Ihab F. and Ouzzani, Mourad and Papotti, Paolo and Stonebraker, Michael},
  year      = {2016},
  booktitle = {2016 IEEE 32nd International Conference on Data Engineering (ICDE)},
  doi       = {10.1109/ICDE.2016.7498319},
  number    = {},
  pages     = {1134-1145},
  volume    = {}
}

@dataset{gittables,
  keywords  = {datasets},
  title     = {GitTables 1.7M},
  author    = {Madelon Hulsebos and
               Çağatay Demiralp and
               Paul Groth},
  year      = 2021,
  url       = {https://doi.org/10.5281/zenodo.4943312},
  doi       = {10.5281/zenodo.4943312},
  month     = jun,
  publisher = {Zenodo},
  version   = {0.0.4}
}

@inproceedings{gordian,
  keywords  = {existingTechniques},
  title     = {GORDIAN: Efficient and scalable discovery of composite keys},
  author    = {Sismanis, Yannis and Brown, Paul and Haas, Peter and Reinwald, Berthold},
  year      = {2006},
  booktitle = {VLDB},
  month     = {01},
  pages     = {691-702}
}

@article{mlTutorial,
  keywords     = {MLTutorial},
  title        = {Machine Learning with Python: Classification (complete tutorial)},
  author       = {Mauro Di Pietro},
  year         = {2020},
  url          = {https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec},
  journaltitle = {towardsdatascience.com}
}

@article{dataProfilingMetanome,
  keywords   = {starter},
  title      = {Data Profiling with Metanome},
  author     = {Papenbrock, Thorsten and Bergmann, Tanja and Finke, Moritz and Zwiener, Jakob and Naumann, Felix},
  year       = {2015},
  url        = {http://dx.doi.org/10.14778/2824032.2824086},
  acmid      = {2824086},
  doi        = {10.14778/2824032.2824086},
  issn       = {2150-8097},
  issue_date = {August 2015},
  journal    = {Proc. VLDB Endow.},
  month      = {Aug},
  number     = {12},
  numpages   = {4},
  pages      = {1860--1863},
  publisher  = {VLDB Endowment},
  volume     = {8}
}

@article{profilingRelData,
  keywords = {starter},
  title    = {Profiling relational data: a survey},
  author   = {Abedjan, Ziawasch
              and Golab, Lukasz
              and Naumann, Felix},
  year     = {2015},
  url      = {https://doi.org/10.1007/s00778-015-0389-y},
  abstract = {Profiling data to determine metadata about a given dataset is an important and frequent activity of any IT professional and researcher and is necessary for various use-cases. It encompasses a vast array of methods to examine datasets and produce metadata. Among the simpler results are statistics, such as the number of null values and distinct values in a column, its data type, or the most frequent patterns of its data values. Metadata that are more difficult to compute involve multiple columns, namely correlations, unique column combinations, functional dependencies, and inclusion dependencies. Further techniques detect conditional properties of the dataset at hand. This survey provides a classification of data profiling tasks and comprehensively reviews the state of the art for each class. In addition, we review data profiling tools and systems from research and industry. We conclude with an outlook on the future of data profiling beyond traditional profiling tasks and beyond relational databases.},
  day      = {01},
  doi      = {10.1007/s00778-015-0389-y},
  issn     = {0949-877X},
  journal  = {The VLDB Journal},
  month    = {Aug},
  number   = {4},
  pages    = {557-581},
  volume   = {24}
}

@article{ducc,
  keywords   = {starter, existingTechniques},
  title      = {Scalable Discovery of Unique Column Combinations},
  author     = {Heise, Arvid and Quian\'{e}-Ruiz, Jorge-Arnulfo and Abedjan, Ziawasch and Jentzsch, Anja and Naumann, Felix},
  year       = {2013},
  url        = {https://doi.org/10.14778/2732240.2732248},
  abstract   = {The discovery of all unique (and non-unique) column combinations in a given dataset is at the core of any data profiling effort. The results are useful for a large number of areas of data management, such as anomaly detection, data integration, data modeling, duplicate detection, indexing, and query optimization. However, discovering all unique and non-unique column combinations is an NP-hard problem, which in principle requires to verify an exponential number of column combinations for uniqueness on all data values. Thus, achieving efficiency and scalability in this context is a tremendous challenge by itself.In this paper, we devise Ducc, a scalable and efficient approach to the problem of finding all unique and non-unique column combinations in big datasets. We first model the problem as a graph coloring problem and analyze the pruning effect of individual combinations. We then present our hybrid column-based pruning technique, which traverses the lattice in a depth-first and random walk combination. This strategy allows Ducc to typically depend on the solution set size and hence to prune large swaths of the lattice. Ducc also incorporates row-based pruning to run uniqueness checks in just few milliseconds. To achieve even higher scalability, Ducc runs on several CPU cores (scale-up) and compute nodes (scale-out) with a very low overhead. We exhaustively evaluate Ducc using three datasets (two real and one synthetic) with several millions rows and hundreds of attributes. We compare Ducc with related work: Gordian and HCA. The results show that Ducc is up to more than 2 orders of magnitude faster than Gordian and HCA (631x faster than Gordian and 398x faster than HCA). Finally, a series of scalability experiments shows the efficiency of Ducc to scale up and out.},
  doi        = {10.14778/2732240.2732248},
  issn       = {2150-8097},
  issue_date = {December 2013},
  journal    = {Proc. VLDB Endow.},
  month      = {dec},
  number     = {4},
  numpages   = {12},
  pages      = {301–312},
  publisher  = {VLDB Endowment},
  volume     = {7}
}